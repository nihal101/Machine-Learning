{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of data_preprocessing_tools.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37puETfgRzzg",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoRP98MpR-qj",
        "colab_type": "text"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtSPATlPpHCZ",
        "colab_type": "text"
      },
      "source": [
        "We have to import these three library for data preprocessing.\n",
        "1.numpy-:numpy stands for (Numerical Python) and it is a library for working with arrays.\n",
        "\n",
        "2.pandas-:pandas is an open source library that is built on top of numpy library.It is python package that provide various data structure and operation for manuipulating numerical. It is also used to import data set.\n",
        "\n",
        "3.matplotlib-: matplotlib is a python library used for 2D graphics in python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Uvc4FFT-lHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RopL7tUZSQkT",
        "colab_type": "text"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFjNRYEOieI7",
        "colab_type": "text"
      },
      "source": [
        "In first line we call method \"read_csv\" which present in pandas and it takes argument that is path of dataset.\n",
        "\n",
        "X is known as design matrix which contain matrix of input feature and it can formed by taking all coloumn except last(because last column is outfeature)\n",
        "\n",
        "y contain last column of out dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtNMJU5vDDk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=pd.read_csv('Data.csv')\n",
        "X=dataset.iloc[:,:-1].values\n",
        "y=dataset.iloc[:,-1].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7S7xOubjGAz",
        "colab_type": "text"
      },
      "source": [
        "This is how design matrix X looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqM11BpfDdOv",
        "colab_type": "code",
        "outputId": "aad1c818-c889-409e-eb40-66e45a95c749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqF9lDFQjPz7",
        "colab_type": "text"
      },
      "source": [
        "This is how output feature(last column) looks like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3j1VfXuDfSv",
        "colab_type": "code",
        "outputId": "ded64ca6-2804-49fa-ca06-8c5257aecab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhfKXNxlSabC",
        "colab_type": "text"
      },
      "source": [
        "## Taking care of missing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEn2rbYCjX7s",
        "colab_type": "text"
      },
      "source": [
        "In design matrix X we can some see some field where are written \"nan\" which means null values. So before going to apply out machine learning model on dataset we have to fill thsese null field.We can do that in different approach.\n",
        "\n",
        "I-:fill with mean value.\n",
        "II-:fill with median value.\n",
        "III-:fill with most frequent element in X.\n",
        "\n",
        "Here I am going to 'mean' strategy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsXle9FcJVkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
        "imputer.fit(X[:,1:3])\n",
        "X[:,1:3]=imputer.transform(X[:,1:3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vii7nlwkOnP",
        "colab_type": "text"
      },
      "source": [
        "After filling null field with mean value our design matrix will be changed and looks like as below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j0frPWmJ6ww",
        "colab_type": "code",
        "outputId": "86ac6bc8-9f09-4b38-e33e-f6662280c796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CriG6VzVSjcK",
        "colab_type": "text"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhSpdQWeSsFh",
        "colab_type": "text"
      },
      "source": [
        "### Encoding the Independent Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li5C_1Elka12",
        "colab_type": "text"
      },
      "source": [
        "It may be out data set may contain some feature(column) in categorical fashion.(In out data set country name and purchased column contain categorical data). So we have to encode it in numerical Type. There are three ways for that.\n",
        "\n",
        "I-:Integer Coding (\"Where each unique label is mapped to an integer\")\n",
        "\n",
        "II-:One Hot Encoding (\"Where each label is mapped to binary number\")\n",
        "\n",
        "III-:Learned Embedding \n",
        "\n",
        "Here I am using One Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s2VCC8TmZtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers =[('encode',OneHotEncoder(),[0])] , remainder = 'passthrough')\n",
        "X=np.array(ct.fit_transform(X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGIBTOJXleJj",
        "colab_type": "text"
      },
      "source": [
        "After applying One Hot Encoding out design matrix will be completely changed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfZqkfOBnSJi",
        "colab_type": "code",
        "outputId": "e33e27ca-6de7-40fb-e470-f92da3883046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXh8oVSITIc6",
        "colab_type": "text"
      },
      "source": [
        "### Encoding the Dependent Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avm5-9QtlwqJ",
        "colab_type": "text"
      },
      "source": [
        "Like design matrix we have also apply One Hot Encoding for our output feature it it contain any categorical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8Rx7k5go-gO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpnuwAFbl-zz",
        "colab_type": "text"
      },
      "source": [
        "Our new output feature after One Hot Encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48EvVHOspb2X",
        "colab_type": "code",
        "outputId": "bbb64b4a-c52b-479b-d81c-92cc5db939ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb_vcgm3qZKW",
        "colab_type": "text"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So7UISqBmJTb",
        "colab_type": "text"
      },
      "source": [
        "We have to divide out data set into two part. first part that is called Training Set and it is used to train out model. Second part is called test_test which used to test the model how accurately predict output. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4-u15cgwnja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9P8zzKHmrQz",
        "colab_type": "text"
      },
      "source": [
        "It print Training data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6RZGEDWw44_",
        "colab_type": "code",
        "outputId": "759d51e7-c9da-46d6-ab67-3ef9d6287a8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ihCdLkow5ED",
        "colab_type": "code",
        "outputId": "50360252-ebe4-4eb7-b5ee-e02f12f80a22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDy3RD3Mmwl0",
        "colab_type": "text"
      },
      "source": [
        "It print Test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycAcfRl2w5Oe",
        "colab_type": "code",
        "outputId": "4f3b55ea-9024-431b-dfb1-bc57ccb3e41e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzsY7iRcw5co",
        "colab_type": "code",
        "outputId": "07dcd1da-7083-4fa7-d417-1a9bbe7bb4ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpGqbS4TqkIR",
        "colab_type": "text"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrjFv52Hm018",
        "colab_type": "text"
      },
      "source": [
        "Feature Scalling is an important step of data preprocessing. Feature Scaling makes all data in such way that they lie in same scale usually -3 to +3.\n",
        "\n",
        "In out data set some field have small value and some field have large value. If we apply out machine learning model without feature scaling then prediction our model have high cost(It does because small value are dominated by large value). \n",
        "So before apply model we have to perform feature scaling.\n",
        "\n",
        "We can perform feature scaling in two ways.\n",
        "\n",
        "I-:Standardizaion\n",
        "    x=(x-mean(X))/standard deviation(X)\n",
        "II-:Normalization-:\n",
        "    x=(x-min(X))/(max(X)-min(X))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtAOz-mexbcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc =  StandardScaler()\n",
        "X_train[:,3:] = sc.fit_transform(X_train[:,3:])\n",
        "X_test[:,3:] = sc.transform(X_test[:,3:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf3PglLW6C9u",
        "colab_type": "code",
        "outputId": "30f296c1-7bcf-4a28-984c-816fc2bb0cef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
            " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
            " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
            " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
            " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
            " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
            " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
            " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR3_zK0A6DN6",
        "colab_type": "code",
        "outputId": "f4d1987f-67e6-4f58-8a7f-678d349be7bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n",
            " [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}